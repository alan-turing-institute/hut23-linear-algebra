%% -*- fill-column: 72; eval: (auto-fill-mode -1); eval: (visual-fill-column-mode 1); eval: (visual-line-mode 1); eval: (adaptive-wrap-prefix-mode 1) -*-
\documentclass[10pt, a4paper, twocolumn]{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[margin=0.51in]{geometry}
\usepackage{parskip}
\usepackage{tabularx}
\usepackage{array}
\usepackage{changepage}
\usepackage[mathscr]{euscript}

\newcommand{\defn}[1]{\textbf{\textsf{#1}}}
\newcommand{\set}[1]{\mathbold{#1}}
\newcommand{\imag}{\mathrm{i}}
\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\F{\mathbb{F}}
\def\setsep{\mid}
\def\vspan{\text{span}}
\def\enumfix{\mbox{ } \vspace*{-1.2\baselineskip}}
\def\deg{\mathop{\text{deg}}}
\def\dim{\mathop{\text{dim}}}

\newtheoremstyle{break}% name
  {}%          Space above, empty = `usual value'
  {8pt}%       Space below
  {\upshape}%  Body font
  {}%          Indent amount (empty = no indent, \parindent = para indent)
  {\bfseries}% Thm head font
  {.}%         Punctuation after thm head
  {\newline}%  Space after thm head: \newline = linebreak
  {}%          Thm head spec

\theoremstyle{break}
\newtheorem{innerdefinition}{Definition}

\theoremstyle{break}
\newtheorem{innerproperty}{Property}

\theoremstyle{break}
\newtheorem{innernotation}{Notation}

\theoremstyle{break}
\newtheorem{innerresult}{Result}

\theoremstyle{break}
\newtheorem{innerlemma}{Lemma}

\theoremstyle{break}
\newtheorem{innercorollary}{Corollary}

\newenvironment{definition}[1]
  {\renewcommand\theinnerdefinition{#1}\innerdefinition}
  {\endinnerdefinition}

\newenvironment{property}[1]
  {\renewcommand\theinnerproperty{#1}\innerproperty}
  {\endinnerproperty}

\newenvironment{notation}[1]
  {\renewcommand\theinnernotation{#1}\innernotation}
  {\endinnernotation}

\newenvironment{result}[1]
  {\renewcommand\theinnerresult{#1}\innerresult}
  {\endinnerresult}

\newenvironment{lemma}[1]
  {\renewcommand\theinnerlemma{#1}\innerlemma}
  {\endinnerlemma}

\newenvironment{corollary}[1]
  {\renewcommand\theinnercorollary{#1}\innercorollary}
  {\endinnercorollary}

\title{All the rules we know}
\date{13 October 2023}
\author{}

\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{3pt}

\newenvironment{forceindent}{\begin{adjustwidth}{16pt}{}}{\end{adjustwidth}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Chapter 1.A}

\begin{definition}{1.1}[Complex Numbers]
A \defn{complex number}\/ is an ordered pair $(a, b)$, where $a, b \in \R$, but we will write this as $a + bi$.

The set of all complex numbers is denoted by $\C$:
$$
\C = \{ a + bi \setsep a, b \in \R \}.
$$

\defn{Addition and multiplication} on $\C$ are defined by
\begin{align*}
(a + bi) + (c + di) &= (a + c) + (b + d)i, \\
(a + bi)(c + di) &= (ac - bd) + (ad + bc)i;
\end{align*}
here $a, b, c, d \in \R$.
\end{definition}

\begin{property}{1.3}[Properties of real arithmetic]
Intentionally restricted to $\R$ for the sake of the 1.A exercises. Equivalent properties can be derived for $\C$.

\defn{commutativity}
\begin{forceindent}
$\alpha + \beta = \beta + \alpha$ and $\alpha \beta = \beta \alpha$ for all $\alpha, \beta \in \R$;
\end{forceindent}

\defn{associativity}
\begin{forceindent}
$(\alpha + \beta) + \lambda = \alpha + (\beta + \lambda)$ and $(\alpha \beta) \lambda = \alpha (\beta \lambda)$ for all $\alpha, \beta, \lambda \in \R$;
\end{forceindent}

\defn{identities}
\begin{forceindent}
$\lambda + 0 = \lambda$ and $\lambda 1 = \lambda$ for all $\lambda \in \R$;
\end{forceindent}

\defn{additive inverse}
\begin{forceindent}
for every $\alpha \in \R$, there exists a unique $\beta \in \R$ such that $\alpha + \beta = 0$;
\end{forceindent}

\defn{multiplicative inverse}
\begin{forceindent}
for every $\alpha \in \R$ with $\alpha \not= 0$, there exists a unique $\beta \in \R$ such that $\alpha \beta = 1$;
\end{forceindent}

\defn{distributive property}
\begin{forceindent}
$\lambda (\alpha + \beta) = \lambda \alpha + \lambda \beta$ for all $\lambda, \alpha, \beta \in \R$.
\end{forceindent}
\end{property}

\begin{definition}{1.5}[ $-\alpha$, subtraction, $1 / \alpha$, division]
Let $\alpha, \beta \in \C$.

Let $-\alpha$ denote the additive inverse of $\alpha$. Thus $-\alpha$ is the unique complex number such that
$$
\alpha + (-\alpha) = 0.
$$

\defn{Subtraction} on $\C$ is defined by
$$
\beta - \alpha = \beta + (-\alpha).
$$

For $\alpha \not= 0$, let $1 / \alpha$ denote the multiplicative inverse of $\alpha$. Thus $1 / \alpha$ is the unique complex number such that
$$
\alpha (1 / \alpha) = 1.
$$

\defn{Division} on $\C$ is defined by
$$
\beta / \alpha = \beta (1 / \alpha).
$$
\end{definition}

\begin{notation}{1.6}[$\F$]
$\F$ stands for either $\R$ or $\C$.
\end{notation}

\begin{definition}{1.8}[list, length]
Suppose $n$ is a nonnegative integer. A \defn{list} of \defn{length} $n$ is an ordered collection of $n$ elements separated by commas and surrounded by parentheses. A list of length $n$ looks like this:
$$
(x_1, \ldots, x_n ).
$$

Two lists are equal if and only if they have the same length and the same elements in the same order.
\end{definition}

\begin{notation}{1.10}[notation: $n$]
$n$ represents a positive integer.
\end{notation}

\begin{definition}{1.11}[$\F^n$, coordinate]
$\F^n$ is the set of all lists of length $n$ of elements of $F$:
$$
\F^n = \{ (x_1, \ldots, x_n ) \setsep x_j \in \F \text{ for } j = 1, \ldots, n \}.
$$

For $(x_1, \ldots, x_n ) \in \F^n$ and $j \in \{ 1, \ldots, n \}$, we say that $x_j$ is the $j^{\text{th}}$ \defn{coordinate} of $(x_1, \ldots, x_n )$.
\end{definition}

\begin{definition}{1.13}[addition in $\F^n$]
\defn{Addition} in $\F^n$ is defined by adding corresponding coordinates:
$$
(x_1, \ldots, x_n ) + (y_1, \ldots, y_n ) = (x_1 + y_1, \ldots, x_n + y_n ).
$$
\end{definition}

\begin{definition}{1.15}[$0$]
Let $0$ denote the list of length $n$ whose coorinates are all 0:
$$
(0, \ldots, 0 ).
$$
\end{definition}

\begin{definition}{1.17}[additive inverse in $\F^n$]
For $x \in \F^n$, the \defn{additive inverse} of $x$, denoted $-x$, is the vector $-x \in \F^n$ such that
$$
x + (-x) = 0.
$$
In other words, if $x = (x_1, \ldots, x_n)$, then $-x = (-x_1, \ldots, -x_n)$.
\end{definition}

\begin{definition}{1.18}[scalar multiplication in $\F^n$]
The \defn{product} of a number $\lambda$ and a vector in $\F^n$ is computed by multiplying each coordinate of the vector by $\lambda$:
$$
\lambda (x_1, \ldots, x_n) = (\lambda x_1, \ldots, \lambda x_n);
$$
Here $\lambda \in \F$ and $(x_1, \ldots, x_n) \in \F^n$.
\end{definition}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Chapter 1.B}

\begin{definition}{1.19}[addition, scalar multiplication]
An \defn{addition} on a set $V$ is a function that assigns an element $u + v \in V$ to each pair of elements $u, v \in V$.

A \defn{scalar multiplication} on a set $V$ is a function that assigns an element $\lambda v \in V$ to each $\lambda \in \F$ and each $v \in V$.
\end{definition}

\begin{definition}{1.20}[vector space]
A \defn{vector space over $\F$} is a set $V$ along with an addition on $V$ and a scalar multiplication on $V$ such that the following properties hold:

\defn{commutativity}
\begin{forceindent}
$u + v = v + u$ for all $u, v \in V$;
\end{forceindent}

\defn{associativity}
\begin{forceindent}
$(u + v) + w = u + (v + w)$ and $(ab)v = a(bv)$ for all $u, v, w \in V$ and all $a, b \in \F$;
\end{forceindent}

\defn{additive identity}
\begin{forceindent}
there exists an element $0 \in V$ such that $v + 0 = v$ for all $v \in V$;
\end{forceindent}

\defn{additive inverse}
\begin{forceindent}
for every $v \in V$, there exists $w \in V$ such that $v + w = 0$;
\end{forceindent}

\defn{multiplicative identity}
\begin{forceindent}
$1v = v$ for all $v \in V$;
\end{forceindent}

\defn{distributive property}
\begin{forceindent}
$a (u + v) = au + av$ and $(a + b)v = av + bv$ for all $a, b \in \F$ and all $u, v \in V$.
\end{forceindent}
\end{definition}

\begin{definition}{1.21}[vector, point]
Elements of a vector space are called \defn{vectors} or \defn{points}.
\end{definition}

\begin{definition}{1.22}[real vector space, complex vector space]
A vector space over $\R$ is called a \defn{real vector space}.

A vector space over $\C$ is called a \defn{complex vector space}.
\end{definition}

\begin{notation}{1.24}[$\F^S$]
If $S$ is a set, $\F^S$ denotes the set of functions from $S$ to $\F$.

For $f, g \in \F^S$ the \defn{sum} $f + g \in \F^S$ is the function defined by
$$
(f + g)(x) = f(x) + g(x)
$$
for all $x \in S$.

For $\lambda \in \F$ and $f \in \F^S$, the \defn{product} $\lambda f \in \F^S$ is the function defined by
$$
(\lambda f)(x) = \lambda f(x)
$$
for all $x \in S$.
\end{notation}

\begin{notation}{1.28}[$-v, w - v$]
Let $v, w \in V$. Then
\begin{enumerate}
\item $-v$ denotes the additive inverse of $v$;
\item $w - v$ is defined to be $w + (-v)$.
\end{enumerate}
\end{notation}

\begin{notation}{1.29}[$V$]
$V$ denotes a vector space over $\F$.
\end{notation}

\newpage

The following rules can all derived from the definition of a vector space.

\begin{result}{1.26}[unique additive identity]
A vector space has a unique additive identity.
\end{result}

\begin{result}{1.27}[unique additive inverse]
Every element in a vector space has a unique additive inverse.
\end{result}

\begin{result}{1.30}[the number $0$ times a vector]
$0v = 0$ for every $v \in V$.
\end{result}

\begin{result}{1.31}[a number times the vector $0$]
$a0 = 0$ for every $a \in \F$.
\end{result}

\begin{result}{1.32}[the number $-1$ times a vector]
$(-1)v = -v$ for every $v \in V$.
\end{result}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Chapter 1.C}

\begin{definition}{1.33}[subspace]
A subset $U$ of $V$ is called a \defn{subspace} of $V$ if $U$ is also a vector space with the same additive identity, addition, and scalar multiplication as on $V$.
\end{definition}

\begin{definition}{1.36}[sum of subspaces]
Suppose $V_1, \ldots, V_m$ are subspaces of $V$. The \defn{sum} of $V_1, \ldots, V_m$, denoted by $V_1 + \cdots + V_m$, is the set of all possible sums of elements of $V_1, \ldots, V_m$. More precisely:
$$
V_1 + \cdots + V_m = \{v_1 + \cdots + v_m \setsep v_1 \in V_1, \ldots, v_m \in V_m \}.
$$
\end{definition}

\begin{definition}{1.41}[direct sum, $\oplus$]
Suppose $V_1, \ldots, V_m$ are subspaces of $V$.

\begin{enumerate}
\item The sum $V_1 + \cdots + V_m$ is called a \defn{direct sum} if each element of $V_1 + \cdots + V_m$ can be written in only one way as a sum $v_1 + \cdots + v_m$, where each $v_k \in V_k$.
\item If $V_1 + \cdots + V_m$ is a direct sum, then $V_1 \oplus \cdots \oplus V_m$ denotes $V_1 + \cdots + V_m$, with the $\oplus$ notation serving as an indication that this is a direct sum.
\end{enumerate}
\end{definition}

\newpage

The following rules can all be derived from the definitions.

\begin{result}{1.34}[conditions for a subspace]
A subset $U$ of $V$ is a subspace of $V$ if and only if $U$ satifies the following three conditions.

\defn{additive identity}
\begin{forceindent}
$0 \in U$.
\end{forceindent}

\defn{closed under addition}
\begin{forceindent}
$u, w \in U$ implies $u + w \in U$.
\end{forceindent}

\defn{closed under scalar multiplication}
\begin{forceindent}
$a \in \F$ and $u \in U$ implies $au \in U$.
\end{forceindent}
\end{result}

\begin{result}{1.40}[sum of subspaces is the smallest containing subspace]
Suppose $V_1, \ldots, V_m$ are subspaces of $V$. Then $V_1 + \cdots + V_m$ is the smallest subspace of $V$ containing $V_1, \ldots, V_m$.
\end{result}

\begin{result}{1.45}[condition for a direct sum]
Suppose $V_1, \ldots, V_m$ are subspaces of $V$. Then $V_1 + \cdots + V_m$ is a direct sum if and only if the only way to write $0$ as a sum $v_1 + \cdots + v_m$, where each $v_k \in V_k$, is by taking each $v_k$ equal to $0$.
\end{result}

\begin{result}{1.46}[direct sum of two subspaces]
Suppose $U$ and $W$ are subspaces of $V$. Then
$$
U + W \text{ is a direct sum} \Longleftrightarrow U \cap W = \{ 0 \}.
$$
\end{result}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Chapter 2.A}

\begin{notation}{2.1}[list of vectors]
We write lists of vectors without surrounding parantheses.
\end{notation}

\begin{definition}{2.2}[linear combination]
A \defn{linear combination} of a list $v_1, \ldots, v_m$ of vectors in $V$ is a vector of the form
$$
a_1 v_1 + \cdots + a_m v_m,
$$
where $a_1, \ldots, a_m \in \F$.
\end{definition}

\begin{definition}{2.4}[span]
The set of all linear combinations of a list of vectors $v_1, \ldots, v_m$ in $V$ is called the \defn{span} of $v_1, \ldots, v_m$, denoted by $\vspan(v_1, \ldots, v_m)$. In other words
$$
\vspan(v_1, \ldots, v_m) = \{ a_1 v_1 + \cdots + a_m v_m \setsep a_1, \ldots, a_m \in \F \}.
$$

The span of the empty list $(\ )$ is defined to be $\{ 0 \}$.
\end{definition}

\begin{definition}{2.7}[spans]
If $\vspan(v_1, \ldots, v_m)$ equals $V$, we say that the list $v_1, \ldots, v_m$ \defn{spans} $V$.
\end{definition}

\begin{definition}{2.9}[finite-dimensional vector space]
A vector space is called \defn{finite-dimensional} if some list of vectors in it spans the space.
\end{definition}

\begin{definition}{2.10}[polynomial, $\mathscr{P}(\F)$] \enumfix
\begin{enumerate}
\item A function $p : \F \to \F$ is called a \defn{polynomial} with coefficients in $\F$ if there exist $a_0, \ldots, a_m \in \F$ such that
$$
p(z) = a_0 + a_1 z + a_2 z^2 + \cdots + a_m z^m
$$
for all $z \in \F$.
\item $\mathscr{P}(\F)$ is the set of all polynomials with coefficients in $\F$.
\end{enumerate}
\end{definition}

\begin{definition}{2.11}[degree of a polynomial, $\deg\ p$] \enumfix
\begin{enumerate}
\item A polynomial $p \in \mathscr{P}(\F)$ is said to have \defn{degree $m$} if there exist scalars $a_0, a_1, \ldots, a_m \in \F$ with $a_m \not= 0$ such that for every $z \in \F$, we have
$$
p(z) = a_0 + a_1 z + \cdots + a_m z^m.
$$
\item The polynomial that is identically $0$ is said to have degree $-\infty$.
\item The degree of polynomial $p$ is denoted by $\deg\ p$.
\end{enumerate}
\end{definition}

\begin{notation}{2.12}[$\mathscr{P}_m (\F)$]
For $m$ a nonnegative integer, $\mathscr{P}_m (\F)$ denotes the set of all polynomials with coefficients in $\F$ and degree at most $m$.
\end{notation}

\begin{definition}{2.13}[infinite-dimensional vector space]
A vector space is called \defn{infinite-dimensional} if it is not finite-dimensional.
\end{definition}

\newpage

\begin{definition}{2.15}[linearly independent] \enumfix
\begin{enumerate}
\item A list $v_1, \ldots, v_m$ of vectors in $V$ is called \defn{linearly independent} if the only choice of $a_1, \ldots, a_m \in \F$ that makes
$$
a_v v_1 + \cdots + a_m v_m = 0
$$
is $a_1 = \cdots = a_m = 0$.
\item The empty list $(\ )$ is also declared to be linearly independent.
\end{enumerate}
\end{definition}

\begin{definition}{2.17}[linearly dependent] \enumfix
\begin{enumerate}
\item A list of vectors $V$ is called \defn{linearly dependent} if it is not linearly independent.
\item In other words, a list $v_1, \ldots, v_m$ of vectors in $V$ is linearly dependent if there exist $a_1, \ldots, a_m \in \F$, not all $0$, such that $a_1 v_1 + \cdots + a_m v_m = 0$.
\end{enumerate}
\end{definition}

\vspace{17\baselineskip}

The following can be derived from the definitions.

\begin{result}{2.6}[span is the smallest containing subspace]
The span of a list of vectors in $V$ is the smallest subspace of $V$ containing all vectors in the list.
\end{result}

\begin{lemma}{2.19}[linear dependence lemma]
Suppose $v_1, \ldots, v_m$ is a linearly dependent list in $V$. Then there exists $k \in \{ 1, 2, \ldots, m \}$ such that
$$
v_k \in \vspan(v_1, \ldots, v_{k - 1}).
$$
Furthermore, if $k$ satisfies the condition above and the $k$\textsuperscript{th} term is removed from $v_1, \ldots, v_m$, then the span of the remaining list equals $\vspan(v_1, \ldots, v_m)$.
\end{lemma}

\begin{result}{2.22}[length of linearly independent list $\le$ length of spanning list]
In a finite-dimensional vector space, the length of every linearly independent list of vectors is less than or equal to the length of every spanning list of vectors.
\end{result}

\begin{result}{2.25}[finite-dimensional subspaces]
Every subspace of a finite-dimensional vector space is finite-dimensional.
\end{result}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Chapter 2.B}

\begin{definition}{2.26}[basis]
A \defn{basis} of $V$ is a list of vectors in $V$ that is linearly dependent and spans $V$.
\end{definition}

\vspace{5\baselineskip}

\begin{result}{2.28}[criterion for basis]
A list $v_1, \ldots, v_n$ of vectors of $V$ is a basis of $V$ if and only if every $v \in V$ can be written uniquely in the form
$$
v = a_1 v_1 + \cdots + a_n v_n,
$$
where $a_1, \ldots, a_n \in \F$.
\end{result}

\begin{result}{2.30}[every spanning list contains a basis]
Every spanning list in a vector space can be reduced to a basis of the vector space.
\end{result}

\begin{corollary}{2.31}[basis of finite-dimensional vector space]
Every finite-dimensional vector space has a basis.
\end{corollary}

\begin{result}{2.32}[every linearly independent list extends to a basis]
Every linearly independent list of vectors in a finite-dimensional vector space can be extended to a basis of the vector space.
\end{result}

\begin{corollary}{2.33}[every subspace of $V$ is part of a direct sum equal to $V$]
Suppose $V$ is finite-dimensional and $U$ is a subspace of $V$. Then there is a subspace $W$ of $V$ such that $V = U \oplus W$.
\end{corollary}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Chapter 2.C}

\begin{definition}{2.35}[dimension, $\dim V$]
The \defn{dimension} of a finite-dimensional vector space is the length of any basis of the vector space.

The dimension of a finite-dimensional vector space $V$ is denoted by $\dim V$.
\end{definition}

\vspace{2\baselineskip}

\begin{result}{2.34}[basis length does not depend on basis]
Any two bases of a finite-dimensional vector space have the same length.
\end{result}

\begin{result}{2.37}[dimension of a subspace]
If $V$ is finite-dimensional and $U$ is a subspace of $V$, then $\dim U \le \dim V$.
\end{result}

\begin{result}{2.38}[linearly independent list of the right length is a basis]
Suppose $V$ is finite-dimensional. Then every linearly independent list of vectors in $V$ of length $\dim V$ is a basis of $V$.
\end{result}

\begin{corollary}{2.39}[subspace of full dimension equals the whole space]
Suppose that $V$ is finite-dimensional and $U$ is a subspace of $V$ such that $\dim U = \dim V$. Then $U = V$.
\end{corollary}

\begin{result}{2.42}[spanning list of the right length is a basis]
Suppose $V$ is finite-dimensional. Then every spanning list of vectors in $V$ of length $\dim V$ is a basis of $V$.
\end{result}

\begin{result}{2.43}[dimension of sum]
If $V_1$ and $V_2$ are subspaces of a finite-dimensional vector space, then
$$
\dim(V_1 + V_2) = \dim V_1 + \dim V_2 - \dim(V_1 \cap V_2).
$$
\end{result}

\end{document}
