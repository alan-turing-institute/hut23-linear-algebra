\documentclass[10pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{beton}
\usepackage{eulervm}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{microtype}
%\usepackage[medium, compact]{titlesec}
\usepackage[inline]{asymptote}
\DeclareFontSeriesDefault[rm]{bf}{sbc}
% \usepackage{amssymb}
%% Turing grid is 21 columns (of 1cm if we are using A4)
%% Usually 4 "big columns", each of 4 text cols plus 1 gutter col;
%% plus an additional gutter on the left.
\usepackage[left=1cm, textwidth=11cm, marginparsep=1cm, marginparwidth=7cm]{geometry}
\usepackage[Ragged, size=footnote, shape=up]{sidenotesplus}
%% We used to use a two-column layout
% \setlength{\columnsep}{1cm}
\title{Simple optimisation (on vector spaces)}
\author{James Geddes}
\date{\today}
%%
\DeclareBoldMathCommand{\setR}{R}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\eg}{\emph{Example:}}
\newcommand{\ie}{\emph{i.e.}}
\begin{document}
\maketitle

A classic problem is that of finding the location of the minimum of
some real-valued function. It is a hard problem! It is not just that
the function itself might be complicated in some way; the
\emph{domain} of the function might complicated: it could be discrete,
or high-dimensional, or have a complicated shape. All of these can
prevent an analytic solution and impede a numerical one.

Sometimes, however, the domain of the function is, or can be
approximated by, a vector space; and then the problem may be more
tractable.

Fix, once and for all, a finite-dimensional, real vector space, $V$,
and consider a real-valued function, $f\colon V\to \setR$. The problem
at hand is to find $x_\text{min}\in V$ (if one exists) such that
\begin{equation*}
 f(x_\text{min}) \leq f(x) \quad\text{for all $x\in V$}.  
\end{equation*}
Sometimes this problem is expressed by writing
\begin{equation*}
  x_\text{min} = \argmin_{x\in V} f(x).
\end{equation*}

To get a sense for this problem, suppose for the moment that $V$ is
one-dimensional, $V=\setR$, and that $f\colon \setR\to\setR$ is
“sufficiently nice” (for example, a smooth function). We now give a
few simple examples where the minimum can be found without much
difficulty.

\eg{} A constant function, $f(x) = a$. Such a function attains its
minimum value everywhere. To say in another way, there is no unique
point at which it is a minimum.

\eg{} A linear function,\sidenote{There is a slight inconsistency in
  terminology here.  A linear \emph{map} from one vector space to
  another necessarily maps zero to zero, whereas a linear function,
  like this one, may have a constant term.} $f(x) = a + bx$. This
function has no minimum (assuming $b\neq0$). Its value can be made
arbitrarily negative by taking $x$ sufficiently large.

\eg{} A quadratic, $f(x) = a + bx + cx^2$. One way to approach the
general case might be to start with the observation that, at any
minimum of a function $f(x)$, the derivative, $f'(x)$, must be zero
and the second derivative, $f''(x)$, must be strictly
positive.\sidenote{Other values of $f''(x)$ indicate maxima ($f''(x) <
  0$) or “points of inflection” ($f''(x)=0$).} However, for the case
of a quadratic, there is a well-known “trick,” which, as a bonus, also
allows us to determine

\begin{marginfigure}
  \begin{center}
    \asyinclude[width=4cm, height=4cm, keepAspect=false]{quadr.asy}
  \end{center}
\caption{A graph of $f(x) = 9 - 8x + 2x^2$. In the notation of the
  text, $b = -8$ and $c = 2$; hence the minimum of $f(x)$ is at
  $x=-\frac{1}{2}c^{-1}b = 2$. One may also see this by rewriting $f$
  as $f(x) = 2{(x-2)}^2+1$.\label{fig:quadratic}}
\end{marginfigure}

The quadratic case is often solved by making use of a certain “trick,”
rather than by taking derivatives. Suppose we can find numbers $\kappa$,
$\gamma$, and $\xi$ such that
\begin{equation*}
  a + bx + cx^2 = \kappa + \gamma{(x - \xi)}^2.
\end{equation*}
Since adding a constant to a function does not change the
\emph{location} of any mimimum, we have only to find the minimum of
$\gamma{(x-\xi)}^2$. And, since ${(x-\xi)}^2$ is nowhere less than zero, any
extremum will occur when ${(x-\xi)}^2$ is precisely zero; that is,
when~$x = \xi$. That point will be a minimum (rather than a maximum)
only if $\gamma>0$, since then $\gamma{(x-\xi)}^2\geq 0$. Note that, as an immediate
corollary, we have that the minimum is a global minimum.

The values of $\kappa$, $\gamma$, and $\xi$ can be read off from the equation
above: $\gamma=c$ (equating terms in $x^2$); $-2\gamma\xi=b$ (equating terms in
$x$); and the value of $\kappa$ does not matter. This trick is known as
“completing the square.” 

We return, now, to the multidimensional case. Thus, suppose that $V$
is a finite-dimensional, real vector space, not necessarily
one-dimensional. What is the equivalent, on $V$, of a quadratic
function on~$\setR$? We must say what we mean by a constant term, a
linear term, and a quadratic term.

It is clear what is meant by a constant term. A constant function on
$V$ is just a constant.\sidenote{Note, again, that a constant function
  $f(x) = a$ is \emph{not} a linear map $V\to\setR$, since $f(0)\neq 0$.}

It is reasonably clear what is meant by a “linear term.” It is a map,
from the vector space to the reals, which is linear. That is, it is a
linear map, \ie, an element of $\mathcal{L}(V, \setR)$. This space, $\mathcal{L}(V,
\setR)$, itself has the structure of a vector space. It is known as
the \emph{dual} of $V$ and is denoted~$V^*$. The equivalent of a
linear term, “$bx$”, is therefore an expression of the form
$\tilde{b}(x)$, for some $\tilde{b}\in V^*$.
\marginpar{The vector space structure on $V^*$ is as follows. For
  $\tilde{p}, \tilde{q}\in V^*$ and $\alpha\in\setR$, the linear combination
  $\tilde{p}+\alpha\cdot\tilde{q}$ is that element of $V^*$ whose action on any
  vector $x\in V$ is $(\tilde{p}+\alpha\cdot\tilde{q})(x) = \tilde{p}(x) +
  \alpha\tilde{q}(x)$. \sidepar

  Suppose $(e_1, \dotsc, e_n)$ is a basis for~$V$. To define an
  element of $V^*$ it suffices to give its action on a basis
  of~$V$. Define $\tilde{e}^j\in V^*$ by
  \begin{equation*}
      \tilde{e}^j(e_i) = 
      \begin{cases}
        1 & \text{if $i=j$}, \\
        0 & \text{otherwise.}
      \end{cases}
  \end{equation*}
  These $\tilde{e}^j$ are a basis for~$V^*$, known as the dual basis.}

It is less clear what might be meant by a “quadratic term.” It would
seem to involve the “product of a vector with itself,” and that is not
an operation that is obviously available in a general vector space. We
need some structure that will allow us to combine two elements $v, w\in
V$, “respecting the vector space structure of $V$.” Once again, we
make use of the dual space. The idea is to start with $v$, somehow
“carry it across” to $V^*$, and then act with the result on~$w$.

Thus, let $C\colon V\to V^*$ be a linear map from $V$ to its dual. For
any vector $v\in V$, we obtain $C(v)\in V^*$, a linear map from $V$
to~$\setR$. Since an element of $V^*$ is a linear map from $V$
to~$\setR$, we may apply $C(v)$ to $w\in V$ and thereby obtain a number,
$(C(v))(w)$.

In a sense, one can think of $C$ as a map from pairs $(v,w)\in V\times V$ to
the reals. However, the notation is extremely cumbersome. Instead of
$(C(v))(w)$ we shall write $C(v,w)$. Thus, by $C(v, w)$ we shall mean,
“apply $C$ to $v$, obtaining an elemement of $V^*$, and apply this
element to $w$, obtaining a number.” The expression $C(v, w)$ is
“linear in both $v$ and $w$.” For example, $C(\alpha v, \beta w) = \alpha\beta C(v,w)$,
which very much gives $C$ the flavour of a product.

We now say what is meant by a “quadratic term:” it is an expression of
the form $C(v,v)$ for some $C\colon V\to V^*$. 



A linear map $C\colon X\to X^*$ is said to be \emph{symmetric} if
$C(v,w)=C(w,v)$ for all $v$ and~$w$. Consider the identity:
\begin{equation*}
  C(v, w) = \frac{1}{2}\bigl[C(v,w) + C(w,v)\bigr]
  + \frac{1}{2}\bigl[C(v,w) - C(w,v)\bigr].
\end{equation*}
The first term on the right is symmetric. Moreover, the second term on
the right is zero when $w=v$. Thus if we all are interested in is
expressions of the form $C(v,v)$, there is no loss of generality in
considering only symmetric maps.

Taking all the above, a quadratic function on a vector space $X$ is a
function of the form
\begin{equation*}
  f(x) = a - 2\tilde{b}(x) + C(x,x)
\end{equation*}
where $\tilde{b}\in X^*$ and $C\colon X\to X^*$ is a symmetric linear
map. (The factor of $-2$ is conventional and gets rid of a factor of
$-\frac{1}{2}$ later.)

Figure~\ref{fig:bilinear-form} illustrates
the concepts involved.
\begin{marginfigure}
  \begin{center}
    \asyinclude[width=5cm]{bilinear-form.asy}
  \end{center}
\caption{A vector space $V$ and its dual $V^*$, showing an element $x\in
  V$ and its image in $V^*$ under $C$, as well as an element
  $\tilde{b}\in V^*$ and its image in $V$ under~$C^{-1}$.\label{fig:bilinear-form}}
\end{marginfigure}


\end{document}
