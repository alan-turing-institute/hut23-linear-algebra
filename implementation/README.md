# Simple Matrix Multiplication Implementations

## Python implementation

Generates the test files in NumPy npy and npz format
(see [numpy.lib.format](https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html#module-numpy.lib.format)):
```
matrices.npz
matrix-a.npy
matrix-b.npy
matrix-c.npy
```

The `matrices.npz` file contains 512 triples of matrices $a$, $b$ and $c$.
The $a$ and $b$ matrices have height and width ranging between 2 and 8 in every combination that makes sense to allow $a$ and $b$ to be multiplied together.
The $c$ matrices contain the result of the multiplication $c = a * b$.

A random seed is used to ensure the same matrices are generated each time.

The multiplication operation is then benchmarked by performing each of the multiplications 32768 times in serial.
The tests use 64-bit floating-point arithmetic.

To run the code, ensure NumPy is installed, then call:
```
python3 matmul.py
```

## C implementation

This loads in the files generated by `matmul.py` and uses them for unit tests and benchmarking.
The actual multiplication operation can be found in the [`src/operations.c`](matmul-c/src/operations.c) file.

To build you'll need `make`, `gcc` and the `libarchive` developer libraries installed.
On Ubuntu this can be done as follows:
```
sudo apt install make gcc libarchive-dev 
cd matmul-c
make
```

On macOS this can be done as follows.
```
brew install make gcc libarchive
cd matmul-c
make
```

As with the Python implementation the benchmarks use 64-bit floating-point arithmetic (doubles).
To run them on either platform use the following:
```
make test
```

## Racket implementation

Install the dependencies. On macOS:
```
brew install racket
raco pkg install binaryio
```

And on Ubuntu:
```
sudo apt install racket
raco pkg install binaryio
```

Unzip `matrices.npz` to a directory called `matrices` in the same directory.
(I can't get Racket's `unzip` library to work.)
On MacOS or Ubuntu:
```
cd testdata
unzip matrices.npz -d matrices
cd ..
```

And run:
```
cd matmul-racket
racket matmul.rkt
```

## Rust implementation by Ed

This is Ed Chapman's [Rust implementation](https://github.com/edchapman88/matrix_library) included as a submodule.
Ensure the submodule has been updated and that Rust is available.
For benchmarking use the release build.

```
git submodule update --init
cd matmul-rst
cargo run --release
```

## Rust implementation from Hackweek

To run the improved Rust implementation developed during Hackweek, do

```
cd matmul-rst-hackweek
cargo run --release
```

This is a much simplified and streamlined version of the Hackweek code we developed, which could handle tensors with arbitrary numbers of dimensions and do many things beside matmuls.

## R implementation

Install R on Ubuntu:
```
sudo apt install r-base-core
```

Or on macOS:
```
brew install R
```

From hereon in it's the same for both Ubuntu and macOS.
The following arrangement ensures everything is installed in your working directory for easy clean up.

Start an interpreted R session:
```
cd matmul-r
mkdir lib venv r-miniconda
R_LIBS_USER="$PWD/lib" \
  WORKON_HOME="$PWD/venv" \
  RETICULATE_MINICONDA_PATH="$PWD/r-miniconda" \
  R --interactive -q --vanilla
```

From inside the R session install dependencies and run the script.

```
install.packages(c("reticulate", "bench"))
library(reticulate)
virtualenv_create("matmul")
virtualenv_install("matmul", "numpy")
reticulate::install_miniconda()
source("matmul.R")
q()
```

Clean up afterwards by deleting the `lib`, `venv` and `r-miniconda` folders from your working directory.

## Asm implementation

This is a variation on the C implementation so the same instructions apply.

Only an ARM64/aarch64 version has been implemented.

## Julia implementation

Install Julia on Ubuntu:
```
sudo snap install julia --classic
```
Or on macOS:
```
brew install julia
```

Then install dependencies:
```
julia --project=. -E "using Pkg; Pkg.instantiate()"
```

Finally run the benchmarks:
```
julia --project=. matmul.jl
```

## Benchmarking small matrix results

Time to perform 16 777 216 matrix multiply operations for all matrix sizes between 2 × 2 and 10 × 10.

Obtained using the following devices:

1. 12th Gen Intel Core i7-1260P (powered) running Ubuntu 22.04.4, Python 3.10.12 and NumPy 1.25.5.
2. Apple M1 Pro (powered) running macOS 13.6.3, Python 3.12.2 and NumPy 1.24.2.
3. Apple M2 (powered), macOS 14.4, Python 3.12.2, numpy 1.26.4.

### Python

Using Numpy.

| Device       |     s |      ops/s |
|:-------------|------:|-----------:|
| Intel i7     | 39.92 | 420 289.64 |
| Apple M1 Pro | 28.70 | 584 562.19 |
| Apple M2     | 29.37 | 571 142.__ |

### C

| Device       |     s |         ops/s |
|:-------------|------:|--------------:|
| Intel i7     |  1.44 | 11 666 383.42 |
| Apple M1 Pro |  1.54 | 10 873 615.05 |
| Apple M2     |  1.02 | 16 525 369.__ |

### Racket

"Naive" implementation, boxed floats.

| Device       |     s |      ops/s |
|:-------------|------:|-----------:|
| Intel i7     | 37.78 | 444 135.43 |
| Apple M1 Pro | 41.80 | 401 359.20 |
| Apple M2     | 39.36 | 426 272.__ |

"Unsafe" implementation.

| Device       |     s |        ops/s |
|:-------------|------:|-------------:|
| Intel i7     |  5.18 | 3 239 470.17 |
| Apple M1 Pro |  5.37 | 3 127 160.48 |
| Apple M2     |       |              |

### Rust

| Device       |     s |      ops/s |
|:-------------|------:|-----------:|
| Intel i7     | 41.08 | 408 403.51 |
| Apple M1 Pro | 50.61 | 331 473.82 |
| Apple M2     |       |            |

### R

With garbage collection disabled.

| Device       |     s |        ops/s |
|:-------------|------:|-------------:|
| Intel i7     | 12.30 | 1 364 001.30 |
| Apple M1 Pro |  9.26 | 1 797 712.32 |
| Apple M2     |       |              |

With garbage collection enabled.

| Device       |     s |        ops/s |
|:-------------|------:|-------------:|
| Intel i7     | 13.50 | 1 244 058.62 |
| Apple M1 Pro | 10.40 | 1 612 762.75 |
| Apple M2     |       |              |

### Asm

| Device       |     s |         ops/s |
|:-------------|------:|--------------:|
| Intel i7     |   N/A |           N/A |
| Apple M1 Pro |  1.28 | 13 115 540.66 |
| Apple M2     |       |               |

### Julia

"Naive" implementation.

| Device       |     s |         ops/s |
|:-------------|------:|--------------:|
| Intel i7     |  3.30 |  5 081 768.87 |
| Apple M1 Pro |  2.48 |  6 765 298.34 |
| Apple M2     |       |               |

"Blas" implementation.

| Device       |     s |         ops/s |
|:-------------|------:|--------------:|
| Intel i7     |  2.22 |  7 562 284.71 |
| Apple M1 Pro |  2.15 |  7 791 596.40 |
| Apple M2     |       |               |

"Unsafe" implementation.

| Device       |     s |         ops/s |
|:-------------|------:|--------------:|
| Intel i7     |  2.20 |  7 640 012.81 |
| Apple M1 Pro |  2.28 |  7 359 173.67 |
| Apple M2     |       |               |

"Unsafe Preallocate" implementation.

| Device       |     s |         ops/s |
|:-------------|------:|--------------:|
| Intel i7     |  1.84 |  9 097 257.03 |
| Apple M1 Pro |  1.79 |  9 347 138.34 |
| Apple M2     |       |               |

"Octavian" implementation.

| Device       |     s |         ops/s |
|:-------------|------:|--------------:|
| Intel i7     |  0.97 | 17 368 743.29 |
| Apple M1 Pro |  0.97 | 17 274 799.31 |
| Apple M2     |       |               |

## Benchmarking matrix size scaling results

Time to perform matrix multiply operations for square matrices between 2 × 2 and 1024 × 1024.
Comparison between different matrix multiplication approaches.

Obtained using the following devices:

1. 12th Gen Intel Core i7-1260P (powered) running Ubuntu 22.04.4, Python 3.10.12 and NumPy 1.25.5.

Results should be added to the `results.csv` file. Execute `plots.jl` to generate the graph.

![Graph showing increasing matrix dimension against time in seconds to multiply square matrices](./results.svg?raw=true "Time to multiply two square matrices as a function of matrix size")
